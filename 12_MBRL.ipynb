{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alucantonio/data_enhanced_simulation/blob/master/12_MBRL.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Based Reinforcement Learning (MBRL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-based reinforcement learning uses a model of the dynamics of the environment to\n",
    "guide the agent's learning and decision-making. This approach differs from model-free\n",
    "RL, which learns a policy of value function directly from interaction with the environment.\n",
    "\n",
    "The model of the environment is expressed in terms of the environment transition dynamics, $s_{t+1} = f(s_t,\n",
    "a_t)$ (think of a deterministic environment), and the reward function $R(s,a)$. The\n",
    "agent either uses a predefined model or learns one through interactions with the environment. \n",
    "\n",
    "The agent uses the model to simulate trajectories, evaluate potential actions, and\n",
    "**plan** future behavior. Then, the agent optimizes its policy or value function based\n",
    "on the predicted outcomes and periodically interacts with the actual environment to\n",
    "improve the model and correct inaccuracies in its predictions.\n",
    "\n",
    "Advantages of MBRL:\n",
    "\n",
    "- Sample efficiency: by learning and simulating within the model, the agent can reduce the need for extensive interactions with the real environment, making it particularly useful when interactions are costly or limited.\n",
    "- Generalization: a well-learned model can generalize to unseen scenarios and adapt more easily to changes.\n",
    "- Interpretability: the explicit model provides insights into the environment’s dynamics.\n",
    "\n",
    "Challenges:\n",
    "\n",
    "- Model accuracy: errors in the learned model can lead to suboptimal or unsafe decisions (a problem known as “model bias”).\n",
    "- Complexity: learning and maintaining a reliable model can be computationally expensive, especially in high-dimensional or stochastic environments.\n",
    "- Trade-off with exploration: balancing exploration of the real environment and reliance on the model requires careful design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dyna-Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dyna-Q algorithm combines ideas from both model-free RL and model-based planning to\n",
    "increase learning efficiency. Specifically, it employs both real-world experience and simulated experience derived\n",
    "from a learned model of the environment.\n",
    "\n",
    "Key components:\n",
    "1.\tValue function (Q-function)\n",
    "2.\tModel of the environment: it consists of a transition model and a reward model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-code of the algorithm:\n",
    "\n",
    "```pseudo\n",
    "Initialize Q(s, a) arbitrarily\n",
    "Initialize the model (empty initially)\n",
    "\n",
    "Repeat (for each episode or until convergence):\n",
    "    1. Observe the current state s\n",
    "    2. Select action a using an epsilon-greedy policy\n",
    "    3. Execute a, observe reward r and next state s'\n",
    "    4. Update Q(s, a) using the Q-learning update rule\n",
    "    5. Update the model with (s, a, r, s')\n",
    "    6. For n planning steps:\n",
    "        a. Randomly sample (s_sim, a_sim) from the model\n",
    "        b. Predict r_sim, s'_sim using the model\n",
    "        c. Update Q(s_sim, a_sim) using the Q-learning update rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAC-Dyna-Q-like algorithm\n",
    "\n",
    "We can combine an actor-critic model (SAC - Soft Actor Critic) with a planning component\n",
    "based on the model to create a Dyna-Q-like algorithm.\n",
    "\n",
    "Here is the pseudo-code:\n",
    "\n",
    "1. Initialize environment $ \\text{env} $.\n",
    "2. Initialize SAC agent and replay buffer $ \\mathcal{D} $.\n",
    "3. Set $ N_\\text{real\\_episodes}, N_\\text{synthetic\\_samples} $.\n",
    "\n",
    "For $ \\text{episode} $ in $ N_\\text{real\\_episodes} $:\n",
    "1. **Collect real data:**\n",
    "   - Reset environment.\n",
    "   - For each step in the environment:\n",
    "     1. Select action $a_t$ according to the agent's policy\n",
    "     2. Execute $ a_t $, observe $ s_{t+1}, r_t, \\text{done} $.\n",
    "     3. Store $ (s_t, a_t, r_t, s_{t+1}, \\text{done}) $ in $ \\mathcal{D} $.\n",
    "\n",
    "2. **Model-free SAC update:**\n",
    "   - Sample $ (s, a, r, s', \\text{done}) $ from $ \\mathcal{D} $.\n",
    "   - Update value and policy networks using SAC objectives.\n",
    "\n",
    "3. **Generate synthetic data:**\n",
    "   - For $ i $ in $ N_\\text{synthetic\\_samples} $:\n",
    "     1. Sample $ s $ from $ \\mathcal{D} $ or the observation space.\n",
    "     2. Predict action according to the agent's policy\n",
    "     3. Simulate $ s', r $ using the model\n",
    "     4. Store $ (s, a, r, s', \\text{done}) $ in $ \\mathcal{D} $.\n",
    "\n",
    "4. **SAC update with synthetic data:**\n",
    "   - Repeat step 2 with synthetic data added to $ \\mathcal{D} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the `Pendulum` environment with MBRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will implement the SAC-Dyna-Q-like algorithm described above to\n",
    "solve the `Pendulum` environment of `gymnasium`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use Symbolic Regression (see notebook n. 11) to discover the equation for the\n",
    "   evolution of the angular velocity:\n",
    "\n",
    "   $\\theta_{t+1} = f(\\theta_t, a_t)$\n",
    "\n",
    "   where $a_t$ is the action (torque). Compare it with the true dynamics:\n",
    "\n",
    "   $\\theta_{t+1} = \\theta_t + \\Delta t\\frac{3g}{2l}\\sin \\theta_t + \\Delta\n",
    "   t\\frac{3}{ml^2}a_t$\n",
    "   \n",
    "   where $g$ is the gravity acceleration, $l$ is the length of the pendulum, $m$ is the\n",
    "   mass of the pendulum and $\\Delta t$ is the time-step of the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement a `gymnasium` enviroment based on the learned model. Complete the `step`\n",
    "   function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "class ModelEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        self.max_speed = 8\n",
    "        self.max_torque = 2.0\n",
    "        self.dt = 0.05\n",
    "        self.g = g\n",
    "        self.m = 1.0\n",
    "        self.l = 1.0\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.screen_dim = 500\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.isopen = True\n",
    "\n",
    "        high = np.array([1.0, 1.0, self.max_speed], dtype=np.float32)\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-self.max_torque, high=self.max_torque, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        self.observation_space = spaces.Box(low=-high, high=high, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        th, thdot = self.state  # th := theta\n",
    "\n",
    "        dt = self.dt\n",
    "\n",
    "        action = np.clip(action, -self.max_torque, self.max_torque)[0]\n",
    "        costs = angle_normalize(th) ** 2 + 0.1 * thdot**2 + 0.001 * (action**2)\n",
    "\n",
    "        # UPDATE ANGULAR VELOCITY HERE based on the equation found via symbolic regression\n",
    "        # newthdot = ...\n",
    "\n",
    "        newthdot = np.clip(newthdot, -self.max_speed, self.max_speed)\n",
    "        newth = th + newthdot * dt\n",
    "\n",
    "        self.state = np.array([newth, newthdot])\n",
    "\n",
    "        return self._get_obs(), -costs, False, False, {}\n",
    "\n",
    "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        super().reset(seed=seed)\n",
    "        high = np.array([np.pi, 1.])\n",
    "        low = -high\n",
    "        self.state = self.np_random.uniform(low=low, high=high)\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        theta, thetadot = self.state\n",
    "        return np.array([np.cos(theta), np.sin(theta), thetadot], dtype=np.float32)\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def angle_normalize(x):\n",
    "    return ((x + np.pi) % (2 * np.pi)) - np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Complete the function `generate_synthetic_data` that uses an instance of `ModelEnv`\n",
    "   generate samples according to the policy and adds them to\n",
    "   the SAC replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "def generate_synthetic_data(env, policy, replay_buffer, num_samples):\n",
    "    \"\"\"\n",
    "    Generate synthetic transitions using the ModelEnv and add them to the SAC replay buffer.\n",
    "\n",
    "    Parameters:\n",
    "    - env: The ModelEnv instance used to simulate transitions.\n",
    "    - policy: The SAC policy used to predict actions.\n",
    "    - replay_buffer: The SAC replay buffer where synthetic data will be stored.\n",
    "    - num_samples: Number of synthetic transitions to generate.\n",
    "    \"\"\"\n",
    "    for _ in range(num_samples):\n",
    "        # Reset the environment to a random initial state\n",
    "        # ...\n",
    "\n",
    "        # Predict action using the current policy\n",
    "        # ...\n",
    "\n",
    "        # Step through the environment\n",
    "        # ...\n",
    "\n",
    "        if terminated or truncated:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        # Add synthetic transition to the replay buffer\n",
    "        replay_buffer.add(state, next_state, action, reward, done, [{}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solution:\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "def generate_synthetic_data(env, policy, replay_buffer, num_samples):\n",
    "    \"\"\"\n",
    "    Generate synthetic transitions using the ModelEnv and add them to the SAC replay buffer.\n",
    "\n",
    "    Parameters:\n",
    "    - env: The ModelEnv instance used to simulate transitions.\n",
    "    - policy: The SAC policy used to predict actions.\n",
    "    - replay_buffer: The SAC replay buffer where synthetic data will be stored.\n",
    "    - num_samples: Number of synthetic transitions to generate.\n",
    "    \"\"\"\n",
    "    for _ in range(num_samples):\n",
    "        # Reset the environment to a random initial state\n",
    "        state, _ = env.reset()\n",
    "\n",
    "        # Predict action using the current policy\n",
    "        action = policy.predict(state, deterministic=False)[0]\n",
    "\n",
    "        # Step through the environment\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        if terminated or truncated:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        # Add synthetic transition to the replay buffer\n",
    "        replay_buffer.add(state, next_state, action, reward, done, [{}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Complete the function `train` that implements the training loop of the\n",
    "   SAC-Dyna-Q-like algorithm. Check the [docs](https://stable-baselines3.readthedocs.io/en/master/modules/sac.html) of the SAC class for methods needed for\n",
    "   training the policy. Run the training on the `Pendulum-v1` environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "# Create the real environment\n",
    "real_env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "# Create the planning environment\n",
    "model_env = ModelEnv()\n",
    "\n",
    "# Configure logger\n",
    "logger = configure(\"./logs\", [\"stdout\", \"csv\"])\n",
    "\n",
    "# Initialize the SAC agent\n",
    "# model = ...\n",
    "\n",
    "model.set_logger(logger)\n",
    "\n",
    "# Training parameters\n",
    "num_real_episodes = 20\n",
    "steps_per_episode = 200\n",
    "# ...\n",
    "# ...\n",
    "\n",
    "def train():\n",
    "    for episode in range(num_real_episodes):\n",
    "        print(f\"Episode {episode + 1}/{num_real_episodes}\")\n",
    "\n",
    "        # Real environment interaction\n",
    "        state, _ = real_env.reset()\n",
    "\n",
    "        for _ in range(steps_per_episode):\n",
    "            # Predict action using the current policy\n",
    "            # ...\n",
    "\n",
    "            # Take action in the real environment\n",
    "            # ...\n",
    "\n",
    "            # Store real transition in the replay buffer\n",
    "            # ...\n",
    "\n",
    "            # Update the agent using real data\n",
    "            # ...\n",
    "\n",
    "            state = next_state\n",
    "            \n",
    "            if done or truncated:\n",
    "                break\n",
    "\n",
    "        # Generate synthetic data for planning\n",
    "        generate_synthetic_data(model_env, model.policy, model.replay_buffer, num_synthetic_samples)\n",
    "\n",
    "        # Update the agent using synthetic data\n",
    "        # ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "#@title Solution:\n",
    "\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "# Create the real environment\n",
    "real_env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "# Create the planning environment\n",
    "model_env = ModelEnv()\n",
    "\n",
    "# Configure logger\n",
    "logger = configure(\"./logs\", [\"stdout\", \"csv\"])\n",
    "\n",
    "# Initialize the SAC agent\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    real_env,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "model.set_logger(logger)\n",
    "\n",
    "# Training parameters\n",
    "num_real_episodes = 20\n",
    "num_synthetic_samples = 100 \n",
    "steps_per_episode = 200\n",
    "gradient_steps = 2\n",
    "\n",
    "def train():\n",
    "    for episode in range(num_real_episodes):\n",
    "        print(f\"Episode {episode + 1}/{num_real_episodes}\")\n",
    "\n",
    "        total_reward = 0.\n",
    "        # Real environment interaction\n",
    "        state, _ = real_env.reset()\n",
    "\n",
    "        for _ in range(steps_per_episode):\n",
    "            # Predict action using the current policy\n",
    "            action, _ = model.predict(state, deterministic=False)\n",
    "\n",
    "            # Take action in the real environment\n",
    "            next_state, reward, done, truncated, _ = real_env.step(action)\n",
    "\n",
    "            # Store real transition in the replay buffer\n",
    "            model.replay_buffer.add(state, next_state, action, reward, done, [{}])\n",
    "\n",
    "            # Update the agent using real data\n",
    "            model.train(gradient_steps=gradient_steps)\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if done or truncated:\n",
    "                break\n",
    "\n",
    "        print(total_reward)\n",
    "        # Generate synthetic data for planning\n",
    "        generate_synthetic_data(model_env, model.policy, model.replay_buffer, num_synthetic_samples)\n",
    "\n",
    "        # Update the agent using synthetic data\n",
    "        for _ in range(num_synthetic_samples):\n",
    "            model.train(gradient_steps=gradient_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/20\n",
      "-1165.5467805297974\n",
      "Episode 2/20\n",
      "-1200.632108076978\n",
      "Episode 3/20\n",
      "-1176.6643912765708\n",
      "Episode 4/20\n",
      "-857.7098791862674\n",
      "Episode 5/20\n",
      "-1013.8722827144887\n",
      "Episode 6/20\n",
      "-1290.3436113539876\n",
      "Episode 7/20\n",
      "-120.22670171238829\n",
      "Episode 8/20\n",
      "-125.76394965933342\n",
      "Episode 9/20\n",
      "-1.166182503453593\n",
      "Episode 10/20\n",
      "-122.67847458727958\n",
      "Episode 11/20\n",
      "-247.70754221348838\n",
      "Episode 12/20\n",
      "-122.14709014875864\n",
      "Episode 13/20\n",
      "-245.48805022938694\n",
      "Episode 14/20\n",
      "-230.60787759365053\n",
      "Episode 15/20\n",
      "-122.49819153718009\n",
      "Episode 16/20\n",
      "-115.8081584167936\n",
      "Episode 17/20\n",
      "-243.3814160629186\n",
      "Episode 18/20\n",
      "-121.02087896534711\n",
      "Episode 19/20\n",
      "-116.26152193718487\n",
      "Episode 20/20\n",
      "-122.29341828630434\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Play 100 episodes using the trained SAC policy (set `deterministic=True` when using\n",
    "   the `predict` method) and evaluate the average reward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward over 100 evaluation episodes: -154.78459222948953\n"
     ]
    }
   ],
   "source": [
    "#@title Solution:\n",
    "\n",
    "# Evaluate the trained agent\n",
    "# real_env = gym.make(\"Pendulum-v1\", render_mode=\"human\")\n",
    "real_env = gym.make(\"Pendulum-v1\")\n",
    "total_rewards = []\n",
    "for _ in range(100):  # Evaluate for 10 episodes\n",
    "    state, _ = real_env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(state, deterministic=True)\n",
    "        action = np.array(action, dtype=np.float32).reshape(real_env.action_space.shape)\n",
    "        state, reward, terminated, truncated, _ = real_env.step(action)\n",
    "        total_reward += reward\n",
    "        # real_env.render()\n",
    "        if terminated or truncated:\n",
    "            done = True\n",
    "    total_rewards.append(total_reward)\n",
    "\n",
    "print(f\"Average reward over 100 evaluation episodes: {np.mean(total_rewards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Train a PPO agent and compare the average reward over 100 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.13e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 7276      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -1.18e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 4931       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 0          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00272544 |\n",
      "|    clip_fraction        | 0.0151     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | -0.00151   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | 2.44e+03   |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00144   |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 7.25e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.21e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4440         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033956133 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.0306       |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 3.56e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 7.57e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.22e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4262        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004021097 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.00939     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 4.03e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 8.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.21e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4152        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004175023 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.00384     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 3e+03       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 7.01e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.21e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4092         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043482473 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.00119      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 2.91e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 6.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.2e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4049         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051850555 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00043      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 2.68e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 6.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.18e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3966         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049550636 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.000414     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 4.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.2e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3945         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053136386 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.000327     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 4.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.2e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3920        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004244828 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 9.31e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 3.06e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 6.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -1.2e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3906       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00611528 |\n",
      "|    clip_fraction        | 0.0439     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | 0.000108   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | 1.87e+03   |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00274   |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 4.52e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.16e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3897        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005300573 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.000143    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3885        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005595454 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.000113    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 921         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    std                  | 0.933       |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.12e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3875        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002994873 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 6.65e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 953         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.000976   |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 2.58e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.1e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3869         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013237447 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 5.14e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 931          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -7.64e-05    |\n",
      "|    std                  | 0.931        |\n",
      "|    value_loss           | 2.58e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3855        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006902747 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 5.29e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 898         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3853         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029412722 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 3.31e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.923        |\n",
      "|    value_loss           | 4.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3850         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058858655 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 4.02e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 601          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.08e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3847         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048583755 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 4.8e-05      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 655          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.09e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3845         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048320964 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 3.34e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 669          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    std                  | 0.967        |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3843        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004170251 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 1.89e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 891         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3843         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053235334 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 2.19e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 440          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3841         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060961545 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 2.27e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 440          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 1.27e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3840         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037932126 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 2.56e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 450          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000381    |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 1.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3839        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005815393 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 1.85e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 605         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3837         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054776594 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 1.62e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 583          |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3837         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076396223 |\n",
      "|    clip_fraction        | 0.0706       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 1.98e-05     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 405          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 882          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.12e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3835        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005640478 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 3.64e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 424         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.12e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3834        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003437431 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.000529   |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 521         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3833        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005924142 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 657         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3832        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007633279 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 493         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.1e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3832         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054184017 |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 302          |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 495          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.09e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3832         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040554167 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 247          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.915        |\n",
      "|    value_loss           | 511          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.07e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3830         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051434985 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 92.3         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    std                  | 0.884        |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.05e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3830         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073765153 |\n",
      "|    clip_fraction        | 0.063        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    std                  | 0.902        |\n",
      "|    value_loss           | 184          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.04e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3830        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002456699 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.02e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3829        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007037995 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 303         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -999        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3830        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008672947 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 65.9        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.923       |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -980         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3829         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057706055 |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 83.1         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.921        |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -966         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3830         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070409225 |\n",
      "|    clip_fraction        | 0.0867       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 76.6         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -936        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3830        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009570561 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -910         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3829         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068629617 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 58.8         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    std                  | 0.854        |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -893        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3828        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008832727 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 85.1        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -883         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3828         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048081214 |\n",
      "|    clip_fraction        | 0.0685       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -856       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3828       |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01065604 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.825      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | 131        |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    std                  | 0.87       |\n",
      "|    value_loss           | 287        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -814        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3828        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009665384 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -768         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3827         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072803516 |\n",
      "|    clip_fraction        | 0.082        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    std                  | 0.833        |\n",
      "|    value_loss           | 355          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -717        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3827        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007792833 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 98          |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -678        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3827        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012732325 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 0.806       |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -616        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3827        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009072609 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.783       |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -559         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3827         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073924614 |\n",
      "|    clip_fraction        | 0.0658       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00968     |\n",
      "|    std                  | 0.783        |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -506        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3819        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020690639 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    std                  | 0.744       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -452        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3818        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008055618 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 0.728       |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -389        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3818        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020439122 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -335         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3817         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066685798 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | 0.00257      |\n",
      "|    std                  | 0.697        |\n",
      "|    value_loss           | 92.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -297         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3818         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050987224 |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | 0.000213     |\n",
      "|    std                  | 0.69         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -273         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3818         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054534366 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 8.23         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 0.00353      |\n",
      "|    std                  | 0.709        |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -250        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3818        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008382523 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 5.59        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.000107   |\n",
      "|    std                  | 0.711       |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -229        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3818        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008381968 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    std                  | 0.711       |\n",
      "|    value_loss           | 74.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -225        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3818        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015148299 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.000228   |\n",
      "|    std                  | 0.722       |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -219        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010960506 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    std                  | 0.716       |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -214        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014019944 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 7.22        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.00338     |\n",
      "|    std                  | 0.73        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -202        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3816        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005648951 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    std                  | 0.734       |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -202        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008897984 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.942       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -195        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006054631 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 4.95        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    std                  | 0.704       |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -202         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3815         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062297643 |\n",
      "|    clip_fraction        | 0.0977       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 2.11         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | 0.00744      |\n",
      "|    std                  | 0.699        |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -198        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013406929 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 5.73        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.000442   |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -194        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011204912 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.761       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | 0.0037      |\n",
      "|    std                  | 0.669       |\n",
      "|    value_loss           | 6.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -189        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035596617 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.513       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.00903     |\n",
      "|    std                  | 0.665       |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -197        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3815        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005849262 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    std                  | 0.669       |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -196         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3815         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067725107 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.000257    |\n",
      "|    std                  | 0.661        |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -191        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3814        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026226297 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.989      |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 2.9         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.00145     |\n",
      "|    std                  | 0.645       |\n",
      "|    value_loss           | 6.27        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -198         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3814         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065803733 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 4.41         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    std                  | 0.638        |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -201       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3809       |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01751683 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.939     |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | 0.686      |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | 0.0009     |\n",
      "|    std                  | 0.611      |\n",
      "|    value_loss           | 3.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -201        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3809        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014055537 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 2.63        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    std                  | 0.597       |\n",
      "|    value_loss           | 7.33        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -207       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3809       |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00913188 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.905     |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | 1.9        |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | 0.00193    |\n",
      "|    std                  | 0.599      |\n",
      "|    value_loss           | 9.32       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -212         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3809         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066810143 |\n",
      "|    clip_fraction        | 0.0928       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.898       |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 4.12         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.000793    |\n",
      "|    std                  | 0.59         |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -226         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3809         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066127228 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 1.9          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    std                  | 0.581        |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -223        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3809        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008245364 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 2.54        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.000513   |\n",
      "|    std                  | 0.574       |\n",
      "|    value_loss           | 8.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -217        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3809        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016687606 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 3.14        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.583       |\n",
      "|    value_loss           | 6.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -212        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3809        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011468684 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | 0.0011      |\n",
      "|    std                  | 0.562       |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -210       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3808       |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08514695 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.865     |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | 1.57       |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | 0.00957    |\n",
      "|    std                  | 0.581      |\n",
      "|    value_loss           | 6.13       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -213        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3809        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023477083 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.767       |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | 0.00209     |\n",
      "|    std                  | 0.57        |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -204         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3806         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058797547 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.858       |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    std                  | 0.572        |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -204        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3806        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039013512 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -192        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3805        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041179895 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.00324     |\n",
      "|    std                  | 0.544       |\n",
      "|    value_loss           | 3.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -186        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3805        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011216441 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    std                  | 0.548       |\n",
      "|    value_loss           | 5.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -177        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3805        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008696195 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.82       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 5.41        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.000609   |\n",
      "|    std                  | 0.549       |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -169        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3805        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010022025 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.000163   |\n",
      "|    std                  | 0.539       |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -176        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3804        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033237044 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.439       |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | 0.0232      |\n",
      "|    std                  | 0.545       |\n",
      "|    value_loss           | 1.58        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -178         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3804         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028314579 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.815       |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.548        |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -182        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3804        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010696435 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    std                  | 0.54        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -173       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3804       |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 190464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03303887 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.788     |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | 0.255      |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | 0.00195    |\n",
      "|    std                  | 0.526      |\n",
      "|    value_loss           | 1.78       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -170        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3804        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023757804 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.00363     |\n",
      "|    std                  | 0.508       |\n",
      "|    value_loss           | 2.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -171        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3804        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013128957 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.737      |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.443       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    std                  | 0.503       |\n",
      "|    value_loss           | 3.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -174        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3804        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010717207 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.000718   |\n",
      "|    std                  | 0.499       |\n",
      "|    value_loss           | 7.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -180        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3804        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013860437 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 4.15        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.000983   |\n",
      "|    std                  | 0.495       |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3803        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025962614 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 8.19        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.000746   |\n",
      "|    std                  | 0.481       |\n",
      "|    value_loss           | 7.83        |\n",
      "-----------------------------------------\n",
      "Average reward over 100 evaluation episodes: -173.57349117795238\n"
     ]
    }
   ],
   "source": [
    "#@title Solution:\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "# Initialize the PPO model\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",  # Use a Multi-Layer Perceptron policy\n",
    "    env,\n",
    "    learning_rate=7e-4,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=200000)\n",
    "\n",
    "# Evaluate the model\n",
    "episodes = 100\n",
    "total_rewards = []\n",
    "for ep in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done or truncated:\n",
    "            break\n",
    "    total_rewards.append(total_reward)\n",
    "\n",
    "print(f\"Average reward over 100 evaluation episodes: {np.mean(total_rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
